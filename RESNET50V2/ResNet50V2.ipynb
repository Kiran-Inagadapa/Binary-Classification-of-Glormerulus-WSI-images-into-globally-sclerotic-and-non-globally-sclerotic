{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kGqieZGVXcl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import cv2\n",
        "from PIL import Image, ImageEnhance\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOADING DATASET"
      ],
      "metadata": {
        "id": "41xRKXODWSAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MOUNTING THE DRIVE\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir('/content/drive/My Drive/Data/public/')\n",
        "\n",
        "# LOADING DATASET FROM CSV\n",
        "dataset = pd.read_csv('public.csv')\n",
        "\n",
        "# REPLACING IMAGE FILENAME WITH PATH\n",
        "for i in range(0, 5758):\n",
        "  if dataset['ground truth'][i] == 1:\n",
        "    dataset['name'][i] = 'globally_sclerotic_glomeruli/' + dataset['name'][i]\n",
        "  else:\n",
        "    dataset['name'][i] = 'non_globally_sclerotic_glomeruli/' + dataset['name'][i]"
      ],
      "metadata": {
        "id": "3q2fxYeVVhcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPROCESSING DATASET"
      ],
      "metadata": {
        "id": "O51chTDoWVqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE INDEPENDENT VARIABLE SET (IMAGE FILE PATH) AND DEPENDENT VARIABLE SET (LABEL)\n",
        "X = dataset.drop('ground truth', axis = 1)\n",
        "y = dataset['ground truth']\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = 0.15, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.15, random_state = 42)\n",
        "\n",
        "y_test = pd.DataFrame(y_test)\n",
        "y_val = pd.DataFrame(y_val)\n",
        "y_train = pd.DataFrame(y_train)"
      ],
      "metadata": {
        "id": "-j1QGgIaVkdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPROCESSING THE IMAGES BY ENHACING THE COLORS"
      ],
      "metadata": {
        "id": "zNWaioHhWdyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images_by_color(X, y, path):\n",
        "  for i in X.index: # len(X.index) GIVES NO.OF ROWS IN DATAFRAME X\n",
        "    img = cv2.imread(X['name'][i])\n",
        "\n",
        "    img_processed = cv2.resize(img, (224, 224)) # FOR ResNet50\n",
        "\n",
        "    # APPLYING COLOR ENHANCEMENTS\n",
        "    # EQUALIZED HISTOGRAM\n",
        "    img_yuv = cv2.cvtColor((img_processed * 255).astype(np.uint8), cv2.COLOR_RGB2YUV)\n",
        "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
        "    img_processed = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
        "\n",
        "    # CONVERT TO FLOAT32 FOR FURTHER PROCESSING\n",
        "    img_processed = img_processed.astype(np.float32)\n",
        "\n",
        "    # SATURATION AND HUE ENHANCEMENTS\n",
        "    pil_img = Image.fromarray((img_processed * 255).astype(np.uint8))\n",
        "    enhancer = ImageEnhance.Color(pil_img)\n",
        "    pil_img = enhancer.enhance(1.5)  # INCREASED SATURATION BY 1.5 TIMES\n",
        "    img_processed = np.array(pil_img)\n",
        "\n",
        "    if y['ground truth'][i] == 1:\n",
        "      dest_path = os.path.join(path,'sclerotic')\n",
        "    else:\n",
        "      dest_path = os.path.join(path, 'non_sclerotic')\n",
        "\n",
        "    os.makedirs(dest_path, exist_ok=True)\n",
        "\n",
        "\n",
        "    file_name = os.path.basename(X['name'][i])\n",
        "\n",
        "    pil_img.save(os.path.join(dest_path, file_name))\n",
        "\n",
        "# DEFINING BASE DIRECTORY TO STORE FIRST PREPROCESSED DATASET\n",
        "base_dir = '/content/drive/MyDrive/processed_dataset'\n",
        "os.makedirs(base_dir, exist_ok = True)\n",
        "\n",
        "# CREATE TRAIN, VALIDATION, TEST DIRECTORIES\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# CREATE SUBDIRECTOREIS FOR GLOBALLY SCLEROTIC AND NON-GLOBALLY SCLEROTIC\n",
        "subdirs = ['sclerotic', 'non_sclerotic']\n",
        "for subdir in subdirs:\n",
        "    os.makedirs(os.path.join(train_dir, subdir), exist_ok=True)\n",
        "    os.makedirs(os.path.join(validation_dir, subdir), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, subdir), exist_ok=True)\n",
        "\n",
        "# CALL THE PREPROCESSING FUNCTION\n",
        "preprocess_images_by_color(X_train, y_train, train_dir)\n",
        "preprocess_images_by_color(X_val, y_val, validation_dir)\n",
        "preprocess_images_by_color(X_test, y_test, test_dir)"
      ],
      "metadata": {
        "id": "ewh5jPp9VqzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE THE TENSOR DATASETS WITH BATCH SIZE SET TO 32 FOR FIRST PREPROCESSED DATASET\n",
        "batch_size = 32\n",
        "img_size = (224, 224)\n",
        "train_dataset_1 = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
        "                                                            shuffle=True,\n",
        "                                                            color_mode='rgb',\n",
        "                                                            batch_size=batch_size,\n",
        "                                                            image_size=img_size)\n",
        "\n",
        "validation_dataset_1 = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
        "                                                                 shuffle=True,\n",
        "                                                                 color_mode='rgb',\n",
        "                                                                 batch_size=batch_size,\n",
        "                                                                 image_size=img_size)\n",
        "\n",
        "test_dataset_1 = tf.keras.utils.image_dataset_from_directory(test_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           color_mode='rgb',\n",
        "                                                           batch_size=batch_size,\n",
        "                                                           image_size=img_size)\n",
        "\n",
        "# PREFETCHING FOR THE DATASET_1\n",
        "train_dataset_1 = train_dataset_1.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "validation_dataset_1 = validation_dataset_1.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_dataset_1 = test_dataset_1.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "tbItv7MIVq1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFINE DATA AUGUMENTATION PARAMETERS\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip('horizontal_and_vertical'),\n",
        "  tf.keras.layers.RandomRotation(0.15),\n",
        "])"
      ],
      "metadata": {
        "id": "s5yGQBR4Vq41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BUILDING THE MODEL"
      ],
      "metadata": {
        "id": "kGTgwjMFWn1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE THE BASE LEARNER 1 MODEL FROM PRETRAINED RESNET50V2\n",
        "IMG_SHAPE = img_size + (3,)\n",
        "base_model_1 = tf.keras.applications.ResNet50V2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "metadata": {
        "id": "sRJOT2ugV_fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK NO.OF LAYERS IN RESNET50V2\n",
        "print(\"Number of layers in the ResNet50V2: \", len(base_model_1.layers))"
      ],
      "metadata": {
        "id": "fQAIwhOQV_h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNFREEZING TOP 50 LAYERS FOR TRAINING (THE MODEL GETS FITTED TO THE DATASET TO TOP 50 LAYERS ONLY)\n",
        "base_model_1.trainable = True\n",
        "\n",
        "train_from_layers = 140\n",
        "\n",
        "for layer in base_model_1.layers[:train_from_layers]:\n",
        "  layer.trainable = False\n",
        "\n",
        "base_model_1.summary()"
      ],
      "metadata": {
        "id": "kCy1jyFpV_kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFINING TOP TWO LAYERS FOR SETTING OUR OUTPUT REQUIREMENTS\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "\n",
        "# DEFINE ARCHITECTURE OF THE COMPLETE MODEL AFTER AUGUMENTATION AND PREPROCESSING WITH RESPECT TO RESNET50V2\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = tf.keras.applications.resnet_v2.preprocess_input(x)\n",
        "x = base_model_1(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# SUMMARY OF THE UPDATED MODEL\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "z1PNSFy8V_ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPILING THE MODEL\n",
        "base_learning_rate = 0.001\n",
        "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              optimizer = tf.keras.optimizers.SGD(learning_rate=base_learning_rate),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')]\n",
        "              )\n",
        "\n",
        "# SETTING UP CHECKPOINT CALLBACK TO STORE THE BEST PERFORMED MODEL IN EPOCHS\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='run2_best_resnet50V2_model.keras',      # Path where the model will be saved\n",
        "    monitor='val_loss',            # Metric to monitor\n",
        "    save_best_only=True,           # Save only the best model\n",
        "    save_weights_only=False,       # Save the entire model\n",
        "    mode='min',                    # Mode to determine whether the metric should be minimized or maximized\n",
        "    verbose=1                      # Verbosity mode, 0 or 1\n",
        ")\n",
        "\n",
        "# TRAINING THE MODEL\n",
        "history = model_1.fit(train_dataset_1,\n",
        "                    epochs=7,\n",
        "                    validation_data=validation_dataset_1,\n",
        "                    callbacks=[checkpoint_callback]\n",
        "                    )"
      ],
      "metadata": {
        "id": "baSBTI9TV_qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ASSESSING THE RESULTS"
      ],
      "metadata": {
        "id": "SZOnIoC2WsiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PLOTTING THE RESULTS\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mWYSMpNGWJUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVING THE FINAL MODEL (BUT WE'LL USE THE BEST MODEL IDENTIFIED BY CHECKPOINT_CALLBACK)\n",
        "model_1.save('run2_last_resnet50V2_model.keras')"
      ],
      "metadata": {
        "id": "49U60k4bWJX0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}